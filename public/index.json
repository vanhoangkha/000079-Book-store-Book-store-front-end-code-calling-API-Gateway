[
{
	"uri": "/3-deploy-lambda-function/3-1-create-dynamodb-table/",
	"title": "Create DynamoDB table",
	"tags": [],
	"description": "",
	"content": " Open DynamoDB console, then Click Create table Enter table name: Books\nEnter parition key: id Enter sort key: rv_id (review id), type is Number Scroll down to Table settings pattern, select Customize settings\nThen, select On-demand Click Create local Index Enter sort key: name\nEnter index-name: name-index Click Create index Scroll down to the bottom, click Create table So we have created the Books table with the Local secondary index of name-index\nTo add data to the table, you can download the file below: Data\rdynamoDB.json\r(4 ko)\rOpen this file, replace all \u0026lt;AWS-REGION\u0026gt; with the region where you created the S3 book-image-resize-shop bucket, for example: ap-southeast-2 Run the following command in the directory where you save the dynamoDB.json\naws dynamodb batch-write-item --request-items file://dynamoDB.json "
},
{
	"uri": "/4-config-api-gw/4-1-create-methods/",
	"title": "Create methods",
	"tags": [],
	"description": "",
	"content": "Create list API Click /books, then select Create method In the Method detail\nSelect GET method Select Lambda Function for Integration type Check to Use Lambda Proxy integration Enter Lambda function name to be integrated: books_list Click Save Click Create method Create write API Click /books, then select Create method In the Method detail Select GET method Select Lambda Function for Integration type Check to Use Lambda Proxy integration Enter Lambda function name to be integrated: books_list Click Save Click Create method Create delete API Click /books, then select Create Resource For Create Resource\nEnter {id} for Resource name pattern Click Create Resource Click /{id}, then select Create method For Method detail\nSelect method DELETE Select Lambda Function for Integration type Check to Use Lambda Proxy integration Enter Lambda function name to be integrated: book_delete Click Save Click Create method So, we have created the APIs that interact with Lambda functions.\n"
},
{
	"uri": "/1-introduction/",
	"title": "Introduction API Gateway / DynamoDB",
	"tags": [],
	"description": "",
	"content": "Overview Introducing API Gateway Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the \u0026ldquo;front door\u0026rdquo; for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications. API Gateway supports containerized and serverless workloads, as well as web applications.\nAPI Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including traffic management, CORS support, authorization and access control, throttling, monitoring, and API version management. API Gateway has no minimum fees or startup costs. You pay for the API calls you receive and the amount of data transferred out and, with the API Gateway tiered pricing model, you can reduce your cost as your API usage scales.\nAPI Types RESTful APIs Build RESTful APIs optimized for serverless workloads and HTTP backends using HTTP APIs. HTTP APIs are the best choice for building APIs that only require API proxy functionality. If your APIs require API proxy functionality and API management features in a single solution, API Gateway also offers REST APIs.\nWEBSOCKET APIs Build real-time two-way communication applications, such as chat apps and streaming dashboards, with WebSocket APIs. API Gateway maintains a persistent connection to handle message transfer between your backend service and your clients.\nHow API Gateway Works Introducing DynamoDB You can refer to the DynamoDB workshop for more information\nDynamoDB Basic Advanced DynamoDB "
},
{
	"uri": "/",
	"title": "Serverless - Build Frontend to call API Gateway",
	"tags": [],
	"description": "",
	"content": "Serverless - Build Frontend to call API Gateway Overview In the last post, we know how to create and use Lambda functions that interact with S3 and DynamoDB. Next in this series, we build a web application (front-end) to interact with the database through Lambda and API Gateway.\nThe architecture of the application we will build:\nContent Introduction Front-end deployment Deploy Lambda function Config API Gateway Test API by Postman Test API with front-end Cleanup "
},
{
	"uri": "/3-deploy-lambda-function/3-2-deploy-lambda-function/3-2-1-write-data-function/",
	"title": "Writing Lambda function",
	"tags": [],
	"description": "",
	"content": "In this step, we will update the code for the book_create created function in post 1:\nOpen AWS Lambda console, then Click book_create function Copy the below code block into lambda_function.py\nimport boto3\rimport json\rimport base64\rimport io\rimport cgi\rimport os\rs3 = boto3.client(\u0026#39;s3\u0026#39;)\rclient = boto3.resource(\u0026#39;dynamodb\u0026#39;)\rruntime_region = os.environ[\u0026#39;AWS_REGION\u0026#39;]\rdef get_data_from_request_body(content_type, body):\rfp = io.BytesIO(base64.b64decode(body)) # decode\renviron = {\u0026#34;REQUEST_METHOD\u0026#34;: \u0026#34;POST\u0026#34;}\rheaders = {\r\u0026#34;content-type\u0026#34;: content_type,\r\u0026#34;content-length\u0026#34;: len(body),\r}\rfs = cgi.FieldStorage(fp=fp, environ=environ, headers=headers) return [fs, None]\rdef lambda_handler(event, context):\rcontent_type = event[\u0026#39;headers\u0026#39;].get(\u0026#39;Content-Type\u0026#39;, \u0026#39;\u0026#39;) or event[\u0026#39;headers\u0026#39;].get(\u0026#39;content-type\u0026#39;, \u0026#39;\u0026#39;)\rif content_type == \u0026#39;application/json\u0026#39;:\rbook_item = json.loads(event[\u0026#34;body\u0026#34;])\relse:\rbook_data, book_data_error = get_data_from_request_body(\rcontent_type=content_type, body=event[\u0026#34;body\u0026#34;]\r)\rname = book_data[\u0026#39;image\u0026#39;].filename\rimage = book_data[\u0026#39;image\u0026#39;].value\rs3.put_object(Bucket=\u0026#39;book-image-store\u0026#39;, Key=name, Body=image)\rimage_path = \u0026#34;https://{}.s3.{}.amazonaws.com/{}\u0026#34;.format(\u0026#34;book-image-resize-store\u0026#34;, runtime_region, name)\rbook_item = {\r\u0026#34;id\u0026#34;: book_data[\u0026#39;id\u0026#39;].value,\r\u0026#34;rv_id\u0026#34;: 0,\r\u0026#34;name\u0026#34;: book_data[\u0026#39;name\u0026#39;].value,\r\u0026#34;author\u0026#34;: book_data[\u0026#39;author\u0026#39;].value,\r\u0026#34;price\u0026#34; : book_data[\u0026#39;price\u0026#39;].value,\r\u0026#34;category\u0026#34;: book_data[\u0026#39;category\u0026#39;].value,\r\u0026#34;description\u0026#34;: book_data[\u0026#39;description\u0026#39;].value,\r\u0026#34;image\u0026#34;: image_path\r}\rtable = client.Table(\u0026#39;Books\u0026#39;)\rtable.put_item(Item = book_item)\rresponse = {\r\u0026#39;statusCode\u0026#39;: 200,\r\u0026#39;body\u0026#39;: \u0026#39;successfully created item!\u0026#39;,\r\u0026#39;headers\u0026#39;: {\r\u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;,\r\u0026#34;Access-Control-Allow-Headers\u0026#34;: \u0026#34;Access-Control-Allow-Headers, Origin, Accept, X-Requested-With, Content-Type, Access-Control-Request-Method,X-Access-Token, XKey, Authorization\u0026#34;,\r\u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;,\r\u0026#34;Access-Control-Allow-Methods\u0026#34;: \u0026#34;GET,PUT,POST,DELETE,OPTIONS\u0026#34;\r},\r}\rreturn response Then, click Deploy The new code handles the images that the user wants to upload and is saved in the S3 bucket\nIf you create S3 buckets with names different from the lab, replace them in lines 35 and 36 of code\nGive the Lambda function permission to write a file to the S3 bucket.\nClick Configuration tab\nSelect Permissions pattern on the left menu\nClick on the role the function is executing Click on the existing policy that starts with AWSLambdaExecutionRole-\nClick Edit policy\nClick JSON tab and add the blow json block:\n,\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;,\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::book-image-store/*\u0026#34;\r} Click Next\nReview the settings and click Save changes "
},
{
	"uri": "/3-deploy-lambda-function/3-2-deploy-lambda-function/",
	"title": "Deploy Lambda function",
	"tags": [],
	"description": "",
	"content": "In this step, we will create Lambda functions to read, write, and delete data in DynamoDB. Then grant the necessary permissions to those functions.\nNội dung Update writing Lambda function Create listing Lambda function Create deleting Lambda function "
},
{
	"uri": "/2-front-end-deployment/",
	"title": "Front-end deployment",
	"tags": [],
	"description": "",
	"content": "In the first step in this workshop, we will host the web application (front-end) with S3 Static website hosting:\nOpen Amazon S3 console, then Click Create bucket Enter bucket name, such as: fcj-book-shop\nSelect the region closest to you Uncheck block from allowing public access\nCheck to I acknowledge that the current settings might result in this bucket and the objects within becoming public Click Create bucket button Click on created bucket, click Properties tab Scroll down to the bottom, click Edit in Static web hosting pattern Select Enable to enable host web static on S3\nSelect Host a static website for Hosting type Enter index.html for Index document pattern Click Save changes\nAfter successfully enabling, please write down the path of the web Select Permissions tab\nClick Edit of Bucket policy pattern Copy the below code block to Policy\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;,\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::fcj-book-shop/*\u0026#34;\r}\r]\r} Click Save changes Download fcj-serverless-frontend code to device\nOpen command-line/terminal in the folder where you want to save the source code Copy the below commands git clone https://github.com/AWS-First-Cloud-Journey/FCJ-Serverless-Workshop.git\rcd FCJ-Serverless-Workshop\rnpm install --force\ryarn build We have finished building the front-end. Next execute the following command to upload the build folder to S3\naws s3 cp build s3://fcj-book-shop --recursive If your upload fails, configure the access key ID, secret access key, aws region and output format with aws configure command\nResult after uploading: Paste the web link you take notes into your web browser Your application currently has no data returned. To get data from DynamoDB, go to the next section.\n"
},
{
	"uri": "/3-deploy-lambda-function/3-2-deploy-lambda-function/3-2-2-list-data-function/",
	"title": "Listing Lambda function",
	"tags": [],
	"description": "",
	"content": "We will create a Lambda function that reads all the data in the DynamoDB table:\nClick Create function Enter function name, such as: books_list\nSelect Python 3.9 for Runtime pattern Click Create function Copy the below code block and paste to lambda_function.py.\nimport json\rimport boto3\rfrom decimal import *\rfrom boto3.dynamodb.types import TypeDeserializer\rclient = boto3.client(\u0026#39;dynamodb\u0026#39;) serializer = TypeDeserializer()\rclass DecimalEncoder(json.JSONEncoder):\rdef default(self, obj):\rif isinstance(obj, Decimal):\rreturn str(obj)\rreturn json.JSONEncoder.default(self, obj)\rdef deserialize(data):\rif isinstance(data, list):\rreturn [deserialize(v) for v in data]\rif isinstance(data, dict):\rtry:\rreturn serializer.deserialize(data)\rexcept TypeError:\rreturn {k: deserialize(v) for k, v in data.items()}\relse:\rreturn data\rdef lambda_handler(event, context):\rdata_books = client.scan(\rTableName=\u0026#39;Books\u0026#39;,\rIndexName=\u0026#39;name-index\u0026#39;\r)\rformat_data_books = deserialize(data_books[\u0026#34;Items\u0026#34;])\rfor book in format_data_books:\rdata_comment = client.query(\rTableName=\u0026#34;Books\u0026#34;, KeyConditionExpression=\u0026#34;id = :id AND rv_id \u0026gt; :rv_id\u0026#34;, ExpressionAttributeValues={\r\u0026#34;:id\u0026#34;: {\u0026#34;S\u0026#34;: book[\u0026#39;id\u0026#39;]}, \u0026#34;:rv_id\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;0\u0026#34;}\r}\r)\rformat_data_comment = deserialize(data_comment[\u0026#39;Items\u0026#39;])\rprint(data_comment[\u0026#39;Items\u0026#39;])\rbook[\u0026#34;comments\u0026#34;] = format_data_comment\rprint (format_data_books)\rreturn {\r\u0026#34;statusCode\u0026#34;: 200,\r\u0026#34;headers\u0026#34;: {\r\u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;,\r\u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;,\r\u0026#34;Access-Control-Allow-Methods\u0026#34;: \u0026#34;GET,PUT,POST,DELETE, OPTIONS\u0026#34;,\r\u0026#34;Access-Control-Allow-Headers\u0026#34;: \u0026#34;Access-Control-Allow-Headers, Origin,Accept, X-Requested-With, Content-Type, Access-Control-Request-Method,X-Access-Token,XKey,Authorization\u0026#34;\r},\r\u0026#34;body\u0026#34;: json.dumps(format_data_books, cls=DecimalEncoder)\r} Click Deploy Next, give the function permission to read data from DynamoDB\nClick Configuration tab\nSelect Permissions pattern on the left menu\nClick on the role the function is executing Click on the existing policy that starts with AWSLambdaExecutionRole-\nClick Edit policy Click JSON tab and add the below json block:\n,\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;dynamodb:Scan\u0026#34;,\r\u0026#34;dynamodb:Query\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:AWS_REGION:ACCOUNT_ID:table/Books\u0026#34;\r} Replace AWS_REGION with the region where you create the table in DynamoDB, such as: ap-southeast-2\nReplace ACCOUNT_ID with your account id\nClick Review policy Review the settings and click Save changes "
},
{
	"uri": "/4-config-api-gw/4-2-setting-and-cors/",
	"title": "Setting and enable CORS",
	"tags": [],
	"description": "",
	"content": "In this section, we will add binary file support settings and enable CORS for the APIs\nSelect API Settings on the left menu.\nClick Manage media types Click Add binary media type\nEnter multipart/form-data Click Save Changes After the setting is done, back to Resource on the left menu.\nSelect /books resource Select Enable CORS For Enable CORS\nChoose GET and POST method Click Save Select /{id} resource\nSelect Enable CORS For Enable CORS\nChoose DELETE method Click Save To front-end can use APIs, we need deploy APIs.\nSelect / resource Click Deploy API Select New stage Enter stage name, such as: staging\nClick Deploy Take note URL to call API URL of list and write API: URL of delete API: "
},
{
	"uri": "/3-deploy-lambda-function/3-2-deploy-lambda-function/3-2-3-delete-data-function/",
	"title": "Deleting Lambda function",
	"tags": [],
	"description": "",
	"content": "We will create a Lambda function that deletes all items with the specified partition key and sort key in the DynamoDB table. And delete the image file in the S3 bucket:\nClick Create function Enter function name, ví dụ: book_delete\nSelect Python 3.9 for Runtime pattern Click Create function Copy the below code block into lambda_function.py\nimport boto3\rimport json\rs3 = boto3.client(\u0026#39;s3\u0026#39;)\rclient = boto3.resource(\u0026#39;dynamodb\u0026#39;)\rdef get_image_name(image_path):\rstr_image = image_path.split(\u0026#34;/\u0026#34;)\rfor image_path_item in str_image:\rimage_name = image_path_item\rreturn image_name;\rdef lambda_handler(event, context):\rerror = None\rstatus = 200\rdelete_id = event[\u0026#39;pathParameters\u0026#39;]\rdelete_id[\u0026#39;rv_id\u0026#39;] = 0\rtable = client.Table(\u0026#34;Books\u0026#34;)\rimage_path = \u0026#34;\u0026#34;\rtry:\rdata = table.get_item(Key = delete_id)\rimage_path = data[\u0026#39;Item\u0026#39;][\u0026#39;image\u0026#39;]\rimage_name = get_image_name(image_path)\rexcept Exception as e:\rerror = e\rtry:\rresponse = table.query(\rProjectionExpression=\u0026#34;rv_id\u0026#34;, KeyConditionExpression=\u0026#34;id = :id\u0026#34;, ExpressionAttributeValues={\u0026#34;:id\u0026#34;: delete_id[\u0026#39;id\u0026#39;]})\rfor item in response[\u0026#39;Items\u0026#39;]:\rdelete_id[\u0026#39;rv_id\u0026#39;] = item[\u0026#39;rv_id\u0026#39;]\rprint(delete_id)\rtable.delete_item(Key = delete_id)\rprint(image_name)\rs3.delete_object(Bucket=\u0026#39;book-image-resize-store\u0026#39;, Key=image_name)\rexcept Exception as e:\rerror = e\rif error is None:\rmessage = \u0026#39;successfully deleted item!\u0026#39;\relse:\rmessage = \u0026#39;delete item fail\u0026#39;\rstatus = 400\rreturn {\r\u0026#39;statusCode\u0026#39;: status,\r\u0026#39;body\u0026#39;: message,\r\u0026#39;headers\u0026#39;: {\r\u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;,\r\u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39;\r},\r} Click Deploy If you create S3 bucket with name different from the lab, replace it in line 42 of code\nNext, give the Lambda function permission to delete object from the S3 bucket and access to DynamoDB table.\nClick Configuration tab\nSelect Permissions pattern on the left menu\nClick on the role the function is executing Click on the existing policy that starts with AWSLambdaExecutionRole-\nClick Edit policy Click JSON tab and add the blow json block:\n,\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;dynamodb:DeleteItem\u0026#34;,\r\u0026#34;dynamodb:GetItem\u0026#34;,\r\u0026#34;dynamodb:Query\u0026#34;,\r\u0026#34;s3:DeleteObject\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:dynamodb:AWS_REGION:ACCOUNT_ID:table/Books\u0026#34;,\r\u0026#34;arn:aws:s3:::book-image-resize-store/*\u0026#34;\r]\r} Replace AWS_REGION with the region where you create the table in DynamoDB, such as: ap-southeast-2\nReplace ACCOUNT_ID with your account id\nClick Review policy Review the settings and click Save changes "
},
{
	"uri": "/3-deploy-lambda-function/",
	"title": "Deploy Lambda function",
	"tags": [],
	"description": "",
	"content": "In this section, we will create three Lambda functions to write, read and erase data in DynamoDB with Python. If you did the cleanup in workshop 1 of the series, recreate the Lambda function and S3 bucket according to workshop 1\nNội dung Create DynamoDB table Deploy Lambda function "
},
{
	"uri": "/4-config-api-gw/",
	"title": "Config API Gateway",
	"tags": [],
	"description": "",
	"content": "Next, we\u0026rsquo;ll set up the API Gateway to interact with the Lambda functions created in the previous section:\nOpen API Gateway console Scroll down and click Build of REST API pattern Select REST for Protocol\nSelect New API to create a new API Enter REST API name, such as: fcj-serverless-api For API enpoint type: choose Regional Click Create API Click on the API just created, then select Create resource Enter resource name, such as: books\nThen click Create Resource So we have created a new REST API and resource for it. Next, we will create methods to interact with Lambda functions and set them:\nCreate methods Setting and enable CORS "
},
{
	"uri": "/5-test-api-by-postman/",
	"title": "Test APIs by Postman",
	"tags": [],
	"description": "",
	"content": "In this step, we will test operation of the APIs using Postman tool.\nTest the listing API Click + to add a new tab Select GET method Enter URL of the listing API that recorded from the previous step Click Send The returned result is the entire data of the Books table that has been processed Test the writing API Similarly create a new tab\nSelect POST method Enter URL of the writing API that recorded from the previous step In Body pattern, select raw Copy the below text block: {\r\u0026#34;id\u0026#34;: \u0026#34;5\u0026#34;,\r\u0026#34;rv_id\u0026#34;: 0,\r\u0026#34;name\u0026#34;: \u0026#34;Amazon Web Services in Action 2nd Edition\u0026#34;,\r\u0026#34;author\u0026#34;: \u0026#34;Andreas Wittig\u0026#34;,\r\u0026#34;price\u0026#34;: \u0026#34;59.99\u0026#34;,\r\u0026#34;category\u0026#34;: \u0026#34;IT\u0026#34;,\r\u0026#34;description\u0026#34;: \u0026#34;Amazon Web Services in Action, Second Edition is a comprehensive introduction to computing, storing, and networking in the AWS cloud. You\u0026#39;ll find clear, relevant coverage of all the essential AWS services you to know, emphasizing best practices for security, high availability and scalability.\u0026#34;,\r\u0026#34;image\u0026#34;: \u0026#34;https://book-image-resize-shop.s3.ap-southeast-2.amazonaws.com/aws.jpg\u0026#34;\r} Wait a moment, see the results returned Open Books table in DynamoDB console to check data\nBefore call the write API After call the write API Test the deleting API Since the delete Lambda function on execution deletes images uploaded by the user, we manually upload the images to the S3 bucket so the API can run properly.\nOpen Amazon S3 console\nClick book-image-shop bucket, then Click Upload Click Add files Download the image below aand select it to upload S3 Image\raws.jpg\r(24 ko)\rClick Upload After the upload is done, switch to book-image-resize-shop bucket to check. This is execution result of reszie_image Lambda funtion Back to Postman, add a new tab to call the delete API\nSelect DELETE method Enter URL of the deleting API that recorded from the previous step, replace /{id} with /5 Click Send Check the returned result: Open Books table in DynamoDB console to check data Open book-image-resize-shop bucket to check object. The aws.jpg is deleted "
},
{
	"uri": "/6-test-front-end/",
	"title": "Test APIs with front-end",
	"tags": [],
	"description": "",
	"content": "After testing that the APIs work properly with Postman, we will test the APIs that are called with the front-end built from part 2.\nOpen config.js in fcj-serverless-frontend folder that downloaded from part 2\nChange value of APP_API_URL with your URL: Open App.js in fcj-serverless-frontend/src/, change value of isAdmin with true\nRun the command lines under here:\nyarn build\raws s3 cp build s3://fcj-book-store --recursive Paste the endpoint of S3 static web into your browser. The app already shows the book information, but still no pictures because we haven\u0026rsquo;t uploaded the pictures yet. So the listing API is working properly\nTest writing API\nClick Management tab\nClick Update Edit whatever you want except id\nClick Choose image\nUpload the below image to the bucket: Image\rDockerInAction.jpeg\r(33 ko)\rClick Update\nClick OK Image and information updated Click on the Create new book tab to write new data to the database\nEnter id with 5\nEnter name: Amazon Web Services in Action\nEnter the author: Andreas Wittig\nEnter category: IT\nEnter price: 59.99\nEnter a description: Amazon Web Services in Action, Second Edition is a comprehensive introduction to computing, storing, and networking in the AWS cloud. You\u0026rsquo;ll find clear, relevant coverage of all the essential AWS services you to know, emphasizing best practices for security, high availability, and scalability.\nImage\raws.jpg\r(24 ko)\rPress the Choose File button to upload the image\nPress the Create button\nClick OK Display newly created information Test the deleting API\nClick Management tab\nClick Update Click Delete\nClick OK to confirm delete View results after deleting: no appearing book informtion We have finished building a simple SAM-based web application following the serverless model.\n"
},
{
	"uri": "/7-cleanup/",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " Delete DynamoDB table Open DynamoDB console Select Tables on the left menu Select Books table Click Delete Enter delete and click Delete table Delete S3 bucket Open S3 console Select book-image-resize-store bucket Click Empty Enter permanently delete and click Empty Select fcj-book-store bucket Click Empty Enter permanently delete and click Empty Select book-image-resize-store bucket Click Delete Enter book-image-resize-store and click Delete Select book-image-store bucket Click Delete Enter book-image-store and click Delete Select fcj-book-store bucket Click Delete Enter fcj-book-store and click Delete Delete REST API Open API Gateway console Select fcj-serverless-api Click Actions and select Delete Click Delete Delete Lambda functions Open AWS Lambda console Select book_create function Click Actions Select Delete Enter delete and click Delete Similar to resize_image, books_list, book_create, book_delete function "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]